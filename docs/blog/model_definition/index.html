<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.27">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="author" content="Ricardo Rey-Sáez">
<meta name="dcterms.date" content="2025-10-10">
<meta name="description" content="We often use statistical models without asking what they really are. This post gives a friendly and intuitive explanation of what makes a model statistical, the language it speaks through probability density, and how that language leads to likelihood.">
<title>What Is a Statistical Model? From Density to Likelihood – Ricardo Rey-Sáez</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../logosRRS/favicon.svg" rel="icon" type="image/svg+xml">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-c4fb88a7599af4a42f865486fd59166e.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-53407440417a42589bb34d3db63da45b.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-c4fb88a7599af4a42f865486fd59166e.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-982c3d44e9ba4593c234f9dc8ab5fa15.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-b82443598b08977a55c834da1c3151da.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../site_libs/bootstrap/bootstrap-982c3d44e9ba4593c234f9dc8ab5fa15.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script src="../../site_libs/quarto-contrib/iconify-2.1.0/iconify-icon.min.js"></script>
<script src="../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet"><script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-EX8XBWJEYL"></script><script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-EX8XBWJEYL', { 'anonymize_ip': true});
</script><script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>
<meta property="og:title" content="What Is a Statistical Model? From Density to Likelihood">
<meta property="og:description" content="I learned to fit complex models, yet for a long time I did not think deeply about what modeling means. This post is for people who use models routinely and feel that ideas like probability density or maximum likelihood live in an abstract space you can ignore. Seeing these ideas clearly reveals your data assumptions, helps you build models that better reflect reality, and gives you a practical and informed way to connect theory to data. This is one of those rare topics where a little time now improves everything you do later. So, let’s dive in!">
<meta property="og:image" content="https://ricardoreysaez.github.io/blog/model_definition/cover.svg">
<meta property="og:site_name" content="Ricardo Rey-Sáez">
<meta name="citation_title" content="What Is a Statistical Model? From Density to Likelihood">
<meta name="citation_author" content="Ricardo Rey-Sáez">
<meta name="citation_publication_date" content="2025-10-10">
<meta name="citation_cover_date" content="2025-10-10">
<meta name="citation_year" content="2025">
<meta name="citation_online_date" content="2025-10-10">
<meta name="citation_fulltext_html_url" content="https://ricardoreysaez.github.io/blog/model_definition/">
<meta name="citation_language" content="en">
</head>
<body class="nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    window.setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      window.setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    window.hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(darkModeDefault) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const darkModeDefault = false;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !window.hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
    };
    // Switch to dark mode if need be
    if (window.hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner"><nav class="navbar navbar-expand-lg " data-bs-theme="dark"><div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../logosRRS/navbar_light.svg" alt="" class="navbar-logo"></a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Ricardo Rey-Sáez</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
<li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text"><iconify-icon role="img" inline="" icon="f7:house-fill" aria-label="Icon house-fill from f7 Iconify.design set." title="Icon house-fill from f7 Iconify.design set."></iconify-icon> Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about/index.html"> 
<span class="menu-text"><iconify-icon role="img" inline="" icon="game-icons:throne-king" aria-label="Icon throne-king from game-icons Iconify.design set." title="Icon throne-king from game-icons Iconify.design set."></iconify-icon> About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../CV/index.html"> 
<span class="menu-text"><iconify-icon role="img" inline="" icon="pepicons-pop:cv" aria-label="Icon cv from pepicons-pop Iconify.design set." title="Icon cv from pepicons-pop Iconify.design set."></iconify-icon> CV</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog/index.html"> 
<span class="menu-text"><iconify-icon role="img" inline="" icon="carbon:qq-plot" aria-label="Icon qq-plot from carbon Iconify.design set." title="Icon qq-plot from carbon Iconify.design set."></iconify-icon> Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../research/index.html"> 
<span class="menu-text"><iconify-icon role="img" inline="" icon="iconoir:brain-research" aria-label="Icon brain-research from iconoir Iconify.design set." title="Icon brain-research from iconoir Iconify.design set."></iconify-icon> Research</span></a>
  </li>  
</ul>
</div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav></header><!-- content --><header id="title-block-header" class="quarto-title-block default page-columns"><div id="title-block-header-title" class="quarto-title page-columns page-full page-layout-full featured-image p-4" style="background-image: url(featured.png), url(featured.jpg), url(../featured.jpg);">
<h1 class="title">What Is a Statistical Model? From Density to Likelihood</h1>
<p class="subtitle lead">An accessible explanation of what makes a model statistical, how it expresses probability through density, and how that same logic leads to likelihood.</p>
    <div class="quarto-categories">
        <div class="quarto-category">Statistics</div>
        <div class="quarto-category">Models</div>
        <div class="quarto-category">Maximum Likelihood</div>
      </div>
  </div>

<div>
  <div id="title-block-title-desc" class="description pt-4">
    We often use statistical models without asking what they really are. This post gives a friendly and intuitive explanation of what makes a model statistical, the language it speaks through probability density, and how that language leads to likelihood.
  </div>
</div>

<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author"><a href="https://rreysa.github.io">Ricardo Rey-Sáez</a> <a href="https://orcid.org/0000-0001-6739-2035" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Universidad Autónoma de Madrid
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">October 10, 2025</p>
    </div>
  </div>
  
    
  </div>
  



</header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li>
<a href="#the-statistical-model" id="toc-the-statistical-model" class="nav-link active" data-scroll-target="#the-statistical-model">The statistical model</a>
  <ul class="collapse">
<li><a href="#a-simple-example-age-and-height" id="toc-a-simple-example-age-and-height" class="nav-link" data-scroll-target="#a-simple-example-age-and-height">A simple example: age and height</a></li>
  </ul>
</li>
  <li><a href="#the-components-of-a-statistical-model" id="toc-the-components-of-a-statistical-model" class="nav-link" data-scroll-target="#the-components-of-a-statistical-model">The components of a statistical model</a></li>
  <li>
<a href="#the-common-language-of-statistical-models" id="toc-the-common-language-of-statistical-models" class="nav-link" data-scroll-target="#the-common-language-of-statistical-models">The common language of statistical models</a>
  <ul class="collapse">
<li><a href="#probability-density-or-likelihood" id="toc-probability-density-or-likelihood" class="nav-link" data-scroll-target="#probability-density-or-likelihood">Probability, density or likelihood?</a></li>
  <li><a href="#maximum-likelihood" id="toc-maximum-likelihood" class="nav-link" data-scroll-target="#maximum-likelihood">Maximum Likelihood</a></li>
  </ul>
</li>
  <li><a href="#posterior-reflections4" id="toc-posterior-reflections4" class="nav-link" data-scroll-target="#posterior-reflections4">Posterior Reflections</a></li>
  <li>
<a href="#extra-beyond-the-grid" id="toc-extra-beyond-the-grid" class="nav-link" data-scroll-target="#extra-beyond-the-grid">Extra: beyond the grid</a>
  <ul class="collapse">
<li><a href="#maximum-likelihood-with-optimization-algorithms" id="toc-maximum-likelihood-with-optimization-algorithms" class="nav-link" data-scroll-target="#maximum-likelihood-with-optimization-algorithms">Maximum likelihood with optimization algorithms</a></li>
  <li><a href="#closed-form-maximum-likelihood-solutions" id="toc-closed-form-maximum-likelihood-solutions" class="nav-link" data-scroll-target="#closed-form-maximum-likelihood-solutions">Closed-form maximum likelihood solutions</a></li>
  </ul>
</li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content"><!-- source: https://github.com/gadenbuie/garrickadenbuie-com/blob/main/_partials/title-block-link-buttons/title-block.html --><!-- 
<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title"> 
--><!-- <header id="title-block-header" class="quarto-title-block default page-columns"> --><!-- <div class="quarto-title page-columns page-full featured-image p-4" style="background-image: url(featured.png), url(featured.jpg), url(../featured.jpg);"> --><p><em>Love</em> is probably one of the most familiar words in the world. Ask a room full of people if they know what love is, and almost everyone will say yes. But ask them to define it, and you’ll get as many answers as people in the room, each focusing on different aspects of what it means to love. In fact, we are all aware of this paradox: everyone believes they know what love is, although each person understands it in their own way. The same thing, on a smaller scale, happens with the word <em>model</em> in the scientific community.</p>
<p>There are many “last names” for the word <em>model</em>, such as <em>statistical</em>, <em>theoretical</em>, <em>computational</em>, or <em>predictive</em>, which make it a bit harder to know exactly what someone means when they use it, especially when they forget to mention which species of model they’re talking about. However, they all share a common idea: a model is a simplified representation of reality, a way to describe how we believe something works.</p>
<p>Today we’ll talk about the scientist’s favorite child: <strong>the statistical model</strong>, the one that allows us to draw substantive conclusions from data. This post is written for readers with a background in statistics similar to that of a psychology graduate. Some basic familiarity with <code>R</code> will be helpful, but you can follow along even if you’ve never written code before.</p>
<section id="the-statistical-model" class="level2"><h2 class="anchored" data-anchor-id="the-statistical-model">The statistical model</h2>
<p>The reason we need statistical models is simple: <strong>reality changes.</strong> Not all students perform equally well in statistics, not all patients get better in the same way, and not every day has the same temperature. Even when conditions look identical, the results change. This variability is everywhere and is, in many ways, what makes the world both interesting and complex. Statistical models exist precisely to deal with that variability.</p>
<section id="a-simple-example-age-and-height" class="level3"><h3 class="anchored" data-anchor-id="a-simple-example-age-and-height">A simple example: age and height</h3>
<p>Imagine that we measure the height of a group of people and also record their age. In general, we will see that younger children tend to be shorter and that height increases with age. But that relationship is not perfect: two people of the same age can differ by several centimeters. If we wanted to capture that trend with a formula, we could write a simple linear regression model: <span class="math display">\[
\text{Height}_i = \beta_0 + \beta_1 \cdot \text{age}_i + \varepsilon_i
\]</span></p>
<p>This small equation expresses a simple idea: height increases with age, but never exactly. There is always a margin of error, represented by <span class="math inline">\(\varepsilon_i\)</span>, which reflects natural variability between people. But this variability, this <span class="math inline">\(\varepsilon_i\)</span>, is not a minor detail. It is what makes this model <em>statistical</em> rather than <em>deterministic</em>. In statistics, we assume that this unexplained part, this variability, follows a certain pattern. The most common way to describe that pattern is to <strong>assume</strong> that the errors follow a normal distribution with mean zero and some standard deviation, which we call <span class="math inline">\(\sigma_\varepsilon\)</span>: <span class="math display">\[
\varepsilon_{i}\sim\mathrm{Normal}\left(\mu = 0,\;\sigma = \sigma_\varepsilon\right)
\]</span></p>
<p>This means that, on average, the model does not make systematic errors (because the mean of the errors is zero) and that the variability of those differences can be summarized by a single parameter, <span class="math inline">\(\sigma_\varepsilon\)</span>.</p>
<p>Now I am going to do a magic trick. The two equations we just wrote can be summarized in a single, simpler one that reflects the same idea:</p>
<p><span class="math display">\[
\text{Height}_i \sim \mathrm{Normal}\left(\mu =\beta_0+\beta_1\cdot\text{age}_i,\;\sigma = \sigma_\varepsilon\right)
\]</span></p>
<p>This notation reads as follows: the height of person <span class="math inline">\(i\)</span> follows a normal distribution whose mean is <span class="math inline">\(\beta_0 + \beta_1 \cdot \text{age}_i\)</span> and whose standard deviation is <span class="math inline">\(\sigma_\varepsilon\)</span>. In other words, the model specifies a <strong>conditional distribution</strong> for height given age. That is, <strong>for each value of age</strong>, height follows a normal distribution with a different mean but <strong>the same dispersion around that mean.</strong> Therefore, people of the same age share the same conditional distribution.</p>
<p>It may sound abstract, but it becomes much clearer when we draw it. The figure below shows the three conditional distributions of height for ages 5, 10, and 20.</p>
<div class="cell" data-renderings="[&quot;light&quot;,&quot;dark&quot;]">
<div class="light-content">
<p><a href="index_files/figure-html/unnamed-chunk-2-1..light.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="index_files/figure-html/unnamed-chunk-2-1..light.svg" class="img-fluid" width="672"></a></p>
</div>
<div class="dark-content">
<p><a href="index_files/figure-html/unnamed-chunk-2-2..light.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="index_files/figure-html/unnamed-chunk-2-2..light.svg" class="img-fluid" width="672"></a></p>
</div>
</div>
<p>What the model tells us is <strong>which</strong> <u><strong>ranges of height</strong></u> <strong>have higher or lower probability given a certain age</strong><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. For instance, for a 20-year-old, the probability of being somewhere around 175 cm is much greater than the probability of being around 100 cm (though the latter is not zero). This is the kind of information the model provides: <strong>a quantitative description of the probability assigned to different ranges of outcomes, given (or not) a set of predictors.</strong></p>
<p>In other words, <u><strong>the model speaks the language of probability</strong></u>, as we will see in more detail later on. And this is, in fact, the fundamental idea of a statistical model: <strong>we assign a probability distribution to our outcome variable, height.</strong> In our example, this distribution is a <strong>conditional distribution</strong>: <u><strong>for each age value, height has its own distribution</strong></u>, <strong>but that is not a requirement.</strong> We can also specify models that do not depend on other variables (often called <em>unconditional</em> or <em>marginal</em> distributions), although they are usually less informative.</p>
</section></section><section id="the-components-of-a-statistical-model" class="level2"><h2 class="anchored" data-anchor-id="the-components-of-a-statistical-model">The components of a statistical model</h2>
<p>Since a statistical model is based on assigning a probability distribution to the data, <span class="math inline">\(Y\)</span>, it becomes easier to distinguish its components. For example, the regression model above can be written in general form as: <span class="math display">\[
{\color{seagreen}Y_i} \sim {\color{#7E57C2}\mathrm{Normal}}\!\left(
  {\color{#9a2515}\mu} = {\color{#0197FD}\beta_0} + {\color{#0197FD}\beta_1}\cdot{\color{darkorange}X_i},\,
  {\color{#9a2515}\sigma} = {\color{#0197FD}\sigma_\varepsilon}
\right)
\]</span></p>
<p>This notation condenses, at a glance, all the components that make up a statistical model:</p>
<ol type="1">
<li>A <span style="color:seagreen;"><strong>dependent variable</strong></span> and a <span style="color:#7E57C2;"><strong>probability distribution</strong></span>,</li>
<li>The <span style="color:#9a2515;"><strong>parameters</strong></span> of the selected <span style="color:#7E57C2;"><strong>probability distribution</strong></span>,</li>
<li>The <span style="color:#0197FD;"><strong>estimated parameters</strong></span> that sometimes depend on other <span style="color:darkorange;"><strong>observable</strong></span> or <span style="color:darkorange;"><u><strong>latent variables</strong></u></span>
</li>
</ol>
<p>Once you understand the idea of modeling, you can do almost anything. For example, we could model the variance, <span class="math inline">\(\color{#9a2515}{\sigma}\)</span>, instead of the mean, <span class="math inline">\(\color{#9a2515}{\mu}\)</span>. That would mean we <strong>assume</strong> all people have more or less the same height, regardless of age, and that what changes with age is <strong>the variability of height</strong>.</p>
<p><span class="math display">\[
{\color{seagreen}Y_i} \sim {\color{#7E57C2}\mathrm{Normal}}\!\left(
  {\color{#9a2515}\mu} = {\color{#0197FD}\mu_Y},\,
  {\color{#9a2515}\sigma} = \exp\!\left({\color{#0197FD}\beta_0} + {\color{#0197FD}\beta_1}\cdot{\color{darkorange}X_i}\right)
\right)
\]</span></p>
<p>The exponential function ensures that the standard deviation is not negative. Although a model assuming height does not vary with age would be a candidate for the worst model ever, modeling dispersion can be very useful when there is systematic heteroskedasticity, which is not uncommon in applied research.</p>
<section id="changing-the-distribution-from-normal-to-bernoulli" class="level4"><h4 class="anchored" data-anchor-id="changing-the-distribution-from-normal-to-bernoulli">Changing the distribution: from Normal to Bernoulli</h4>
<p>Moving away from the normal distribution does not really change the logic; it lets us choose a model that better fits our data. Imagine flipping a coin with your right hand (<span class="math inline">\(X_i = 1\)</span>) or left hand (<span class="math inline">\(X_i = 0\)</span>). The outcome can be <strong>heads</strong> (<span class="math inline">\(Y_i=1\)</span>) or <strong>tails</strong> (<span class="math inline">\(Y_i=0\)</span>). For binary outcomes, a normal model is suboptimal: it can predict values outside [0, 1] and doesn’t model probabilities directly. Thus, a better model is</p>
<p><span class="math display">\[
{\color{seagreen}Y_i} \sim {\color{#7E57C2}\mathrm{Bernoulli}}\!\left(
  {\color{#9a2515}p} = \frac{1}{1 + \exp\!\left(-\big(
    {\color{#0197FD}\beta_0} + {\color{#0197FD}\beta_1}\cdot{\color{darkorange}X_i}
  \big)\right)}
\right)
\]</span></p>
<p>This is the well-known <em>logistic regression</em>: modeling a Bernoulli outcome with the logit link. We map the linear predictor, <span class="math inline">\(\beta_0+\beta_1\cdot X_i\)</span>, to a valid probability via the logistic function, <span class="math inline">\(\frac{1}{1+\exp(-x)}\)</span>, which guarantees values are always between 0 and 1.</p>
</section><section id="modeling-counts-poisson-regression" class="level4"><h4 class="anchored" data-anchor-id="modeling-counts-poisson-regression">Modeling counts: Poisson regression</h4>
<p>The same applies when we have count data, such as the number of times you have thought about quitting this post to do something more productive. Suppose I know whether you studied psychology or not (our new variable <span class="math inline">\(X_i\)</span>). The result is a <strong>Poisson regression model</strong>:</p>
<p><span class="math display">\[
{\color{seagreen}Y_i} \sim {\color{#7E57C2}\mathrm{Poisson}}\!\left(
  {\color{#9a2515}\lambda} =
  \exp\!\left(
    {\color{#0197FD}\beta_0} + {\color{#0197FD}\beta_1}\cdot{\color{darkorange}X_i}
  \right)
\right)
\]</span></p>
<p>It might not make the cover of <em>Nature</em>, but it proves that even procrastination can be elegantly captured by a model.</p>
</section><section id="choose-your-own-distribution" class="level4"><h4 class="anchored" data-anchor-id="choose-your-own-distribution">Choose your own distribution</h4>
<p>Although these three regressions are “classical” because they are included in commercial software like SPSS, the modeling idea extends to any probability distribution. For example, if I am analyzing response times in an experimental task, I can use another distribution that fits their asymmetric shape better, such as the <strong>ex-Gaussian distribution</strong>. This distribution represents the convolution of a normal and an exponential distribution, and its parameters are <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma\)</span>, and <span class="math inline">\(\tau\)</span>:</p>
<p><span class="math display">\[
{\color{seagreen}Y_i} \sim {\color{#7E57C2}\text{ex-Gaussian}}\!\left(
  {\color{#9a2515}\mu} = {\color{#0197FD}\beta_0} + {\color{#0197FD}\beta_1}\cdot{\color{darkorange}X_i},\,
  {\color{#9a2515}\sigma} = {\color{#0197FD}\sigma},\,
  {\color{#9a2515}\tau} = {\color{#0197FD}\tau}
\right)
\]</span></p>
<p>As we’ve seen so far, the logic is always the same: you can switch models as easily as you change shoes. The more models you know, the more options you’ll have to find the one that best fits your data.</p>
</section></section><section id="the-common-language-of-statistical-models" class="level2"><h2 class="anchored" data-anchor-id="the-common-language-of-statistical-models">The common language of statistical models</h2>
<p>By now, we have seen that statistical models can take many forms. Some describe heights, others probabilities, counts, or reaction times. They can use normal, Bernoulli, Poisson, or ex-Gaussian distributions. No matter how different they look, they all speak the same language: <strong>probability</strong>.</p>
<p>Every model tells us how probability is spread across possible outcomes. With discrete data, the model assigns a probability to each outcome, which is fairly intuitive. With continuous data, individual points have probability zero, so the model specifies a probability density, describing how probability over ranges of values is allocated. Still, the message remains the same: for the same variable and units, higher probability values (with discrete data) or higher density values (with continuous data) correspond to outcomes to which the model assigns greater support, given its parameters and covariates. And this allows us to achieve two of the most fundamental goals in statistics: <strong>identify, within each model,</strong> <u><strong>the parameter values that maximize the joint likelihood of the whole dataset</strong></u>, and <u><strong>compare models</strong></u> by asking <strong>under which model the observed data have higher joint likelihood.</strong></p>
<p>For example, imagine I have 100 observed values from an exponential distribution with rate <span class="math inline">\(\lambda=2\)</span>:</p>
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Simulate exponential distribution values</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">Y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">rexp</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">100</span>, rate <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We now want to see how three different models assign density values to the same data point under fixed reference parameters. We will use a Normal model (<span class="math inline">\(\mu=1.5\)</span>, <span class="math inline">\(\sigma=1\)</span>), a <span class="math inline">\(\chi^2\)</span> model (<span class="math inline">\(\nu=2\)</span>) and an exponential model (<span class="math inline">\(\lambda=2\)</span>). The Normal and <span class="math inline">\(\chi^2\)</span> parameter values were chosen arbitrarily, simply to illustrate the idea; the exponential one matches the parameter value used to generate the data.</p>
<div class="cell">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Compute density values at the same observed point</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  normal <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">Y</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, mean <span class="op">=</span> <span class="fl">1.5</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,</span>
<span>  chi_sq <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">dchisq</a></span><span class="op">(</span><span class="va">Y</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, df <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>,</span>
<span>  exp    <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">dexp</a></span><span class="op">(</span><span class="va">Y</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, rate <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     normal   chi_sq       exp
1 0.2230692 0.404942 0.8604411</code></pre>
</div>
</div>
<p>For this particular observation, the exponential model assigns the highest density (as you’d expect, since it matches the data-generating process), though this won’t necessarily happen for every observation. To make this more intuitive, the plot below displays the three density curves together, with a dotted vertical line showing our observed value. The height of each curve at that line corresponds exactly to the density values we computed with <code><a href="https://rdrr.io/r/stats/Normal.html">dnorm()</a></code>, <code><a href="https://rdrr.io/r/stats/Chisquare.html">dchisq()</a></code> and <code><a href="https://rdrr.io/r/stats/Exponential.html">dexp()</a></code>.</p>
<div class="cell" data-renderings="[&quot;light&quot;,&quot;dark&quot;]">
<div class="light-content">
<p><a href="index_files/figure-html/unnamed-chunk-5-1..light.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="index_files/figure-html/unnamed-chunk-5-1..light.svg" class="img-fluid" width="672"></a></p>
</div>
<div class="dark-content">
<p><a href="index_files/figure-html/unnamed-chunk-5-2..light.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="index_files/figure-html/unnamed-chunk-5-2..light.svg" class="img-fluid" width="672"></a></p>
</div>
</div>
<p>These three density curves are, in fact, <u><strong>the models themselves</strong></u>. For our <span style="color:seagreen;"><strong>dependent variable</strong></span> (here, y, which takes only one observed value in this simple illustration) we have assigned a a <span style="color:#7E57C2;"><strong>probability distribution</strong></span> (in this case, three different ones), each depending on its own <span style="color:#9a2515;"><strong>parameters</strong></span> (which we deliberately fixed) and <span style="color:darkorange;"><strong>covariates</strong></span> (none in this example).</p>
<p>What matters here isn’t “who wins”, but that <strong>each model speaks the same language</strong> at the very same data point: they all return a density that tells us how plausible that value is under each model. Naturally, this depends on the parameter values. We have set <span class="math inline">\(\lambda = 2\)</span> for the exponential model, matching the data-generating rate; within the same model, different parameter values will yield different densities at the same observed point.</p>
<div class="cell">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Density values at the same observed point for different rates</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  exp_l1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">dexp</a></span><span class="op">(</span><span class="va">Y</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, rate <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,</span>
<span>  exp_l2 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">dexp</a></span><span class="op">(</span><span class="va">Y</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, rate <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>,</span>
<span>  exp_l3 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">dexp</a></span><span class="op">(</span><span class="va">Y</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, rate <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>,</span>
<span>  exp_l4 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">dexp</a></span><span class="op">(</span><span class="va">Y</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, rate <span class="op">=</span> <span class="fl">4</span><span class="op">)</span>,</span>
<span>  exp_l5 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">dexp</a></span><span class="op">(</span><span class="va">Y</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, rate <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    exp_l1    exp_l2    exp_l3    exp_l4    exp_l5
1 0.655912 0.8604411 0.8465605 0.7403589 0.6070129</code></pre>
</div>
</div>
<p>The plot below illustrates how the exponential density curve changes as we vary the rate parameter <span class="math inline">\(\lambda\)</span>. The dotted vertical line marks the observed value, and the height of each curve at that point corresponds to the density values we just computed. As <span class="math inline">\(\lambda\)</span> increases, the model assigns less probability mass to larger <span class="math inline">\(y\)</span> values and higher density near zero.</p>
<div class="cell" data-renderings="[&quot;light&quot;,&quot;dark&quot;]">
<div class="light-content">
<p><a href="index_files/figure-html/unnamed-chunk-7-1..light.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="index_files/figure-html/unnamed-chunk-7-1..light.svg" class="img-fluid" width="672"></a></p>
</div>
<div class="dark-content">
<p><a href="index_files/figure-html/unnamed-chunk-7-2..light.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="index_files/figure-html/unnamed-chunk-7-2..light.svg" class="img-fluid" width="672"></a></p>
</div>
</div>
<p>We could keep trying numbers, right? In fact, we could pick the value of <span class="math inline">\(\lambda\)</span> that gives the highest density value for this first observed response. To see this more clearly, we will vary the rate parameter over a dense grid and check, for the first observation, which value gives the largest density. The code below builds the grid, evaluates the exponential density at that data point for each rate, and returns the rate with the highest value.</p>
<div class="cell">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Grid with 9000 rate values</span></span>
<span><span class="va">lambda_vals</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">10</span>, <span class="fl">.001</span><span class="op">)</span></span>
<span><span class="va">density_vals</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">dexp</a></span><span class="op">(</span><span class="va">Y</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, <span class="va">lambda_vals</span><span class="op">)</span></span>
<span><span class="va">lambda_vals</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.max</a></span><span class="op">(</span><span class="va">density_vals</span><span class="op">)</span><span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2.371</code></pre>
</div>
</div>
<p>And this value is slightly above the true value of <span class="math inline">\(\lambda = 2\)</span>.</p>
<p>Everything we’ve done so far is just for illustration. In practice, <u><strong>no one would compare models or estimate parameters using a single observed value</strong></u>. What we really care about is how the model behaves <u><strong>across the entire dataset</strong></u>. Still, we’ll deliberately stay with this one-point example for a bit longer, since it provides a simple way to introduce the concept of <strong>likelihood</strong>, which is formally defined over the complete dataset.</p>
<section id="probability-density-or-likelihood" class="level3"><h3 class="anchored" data-anchor-id="probability-density-or-likelihood">Probability, density or likelihood?</h3>
<p>Confusion between <strong>likelihood</strong>, <strong>probability</strong>, and <strong>density</strong> is common when one first ventures into statistical modeling. Building on our previous example, we’ll join the infinite number of attempts, in all their versions and languages, to clarify what each of these terms really means.</p>
<p>The difference between probability and density we have already seen:</p>
<ul>
<li>With discrete data, <strong>models assign a probability value</strong> to each possible value.</li>
<li>With continuous data, in contrast, <strong>models assign a density value</strong> to each point, and the probability is obtained by considering ranges of values.</li>
</ul>
<p>However, the difference between <strong>probability or density</strong> and <strong>likelihood</strong> is not in the number we calculate, but in <strong>what we treat as the free variable.</strong></p>
<p>In our first example, we fixed all parameter values to arbitrary numbers (<span class="math inline">\(\mu=1.5\)</span>, <span class="math inline">\(\sigma=1\)</span>, <span class="math inline">\(\nu=2\)</span>, <span class="math inline">\(\lambda=2\)</span>), acting as omnipotent gods, and calculated the density of one observed value. In statistical jargon, this means <u><strong>treating the parameters as fixed values</strong></u> and <u><strong>treating the observed value as a realization of a random variable</strong></u>. In doing so, we answer the question:</p>
<blockquote class="blockquote">
<p><strong>What is the probability (or density) of this observed value, given these parameters?</strong></p>
</blockquote>
<p>Here the focus is on the data under a specific parameter value.</p>
<p>In our second example, we did the opposite: we kept the observed value constant and tested many values of the parameter <span class="math inline">\(\lambda\)</span> to see how the density changed. In statistical jargon, this means <u><strong>treating the parameter as the variable of interest</strong></u> and <u><strong>treating the data as fixed values</strong></u>. Now the focus is on the parameter, and we ask:</p>
<blockquote class="blockquote">
<p><strong>How compatible is each parameter value with the observed data?</strong></p>
</blockquote>
<p>For a fixed observation, <span class="math inline">\(y\)</span>, higher density at that point under a given parameter value means higher likelihood, that is, greater compatibility with the data. In fact, we estimated the parameter value that maximized the density; the only difference is that here, instead of calling it density, we say it maximized the likelihood, even though the number is exactly the same<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>
<p>In case any reader feels unsure at this point, here’s an even clearer illustration:</p>
<div class="cell">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">dexp</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">1</span>, rate <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.3678794</code></pre>
</div>
</div>
<p>For an exponential model, the density evaluated at <span class="math inline">\(x=1\)</span> given <span class="math inline">\(\lambda = 1\)</span> is 0.3678794. At the same time, the likelihood of <span class="math inline">\(\lambda\)</span> evaluated at <span class="math inline">\(\lambda = 1\)</span> given <span class="math inline">\(x=1\)</span> is the same number: 0.3678794. Same value, different role. You can even tell which side of the story we’re on just by the “<u><strong>evaluated at</strong></u>”: it quietly reveals whether we’re treating the data or the parameter as the thing that varies.</p>
</section><section id="maximum-likelihood" class="level3"><h3 class="anchored" data-anchor-id="maximum-likelihood">Maximum Likelihood</h3>
<p>Trying different parameter values until finding the one that maximizes the likelihood is the basic idea of <strong>Maximum Likelihood Estimation.</strong> The key difference is that likelihood is calculated <u><strong>using all the data at once</strong></u>, rather than a single observation. Still, the logic is exactly the same as what we have done so far: it all builds on how the model assigns a density to each individual observation.</p>
<p>The joint likelihood of <span class="math inline">\(n\)</span> independent and identically distributed observations is <strong>the product of the probabilities/densities of each observation:</strong></p>
<p><span class="math display">\[
\mathcal{L}\left({\color{#9a2515}\theta}\mid {\color{seagreen}Y}\right) = \prod^n_{i=1} {\color{#7E57C2}f}\left({\color{seagreen}Y_i}\mid{\color{#9a2515}\theta}\right).
\]</span></p>
<p>Here, <span class="math inline">\({\color{seagreen}Y}\)</span> represents all the observed data, <span class="math inline">\({\color{#7E57C2}f}\left({\color{seagreen}Y_i}\mid{\color{#9a2515}\theta}\right)\)</span> is the probability density (or probability mass) that the model assigns to the value <span class="math inline">\({\color{seagreen}Y_i}\)</span>, and <span class="math inline">\({\color{#9a2515}\theta}\)</span> stands for the parameters of the model. For example, the mean and standard deviation in a normal model. For our exponential example:</p>
<p><span class="math display">\[
\mathcal{L}\left({\color{#9a2515}\lambda}\mid{\color{seagreen}Y}\right)
= \prod^n_{i=1}
{\color{#7E57C2}\mathrm{Exponential}}\!\left(
  {\color{seagreen}Y_i}\mid{\color{#9a2515}\lambda}
\right)
\]</span></p>
<p>Don’t be intimidated by the strange and slightly dramatic look of the equation. Its apparent complexity contrasts with the absolute simplicity of how the very same idea is written in <code>R</code>: it’s just the product of the densities of all observations. Assuming <span class="math inline">\(\lambda = 2\)</span>:</p>
<div class="cell">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Likelihood</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/prod.html">prod</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">dexp</a></span><span class="op">(</span><span class="va">Y</span>, rate <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 4.875431e-16</code></pre>
</div>
</div>
<p>Why a product? Because <strong>we assume that all observations are independent.</strong> Under this assumption, <strong>the joint probability</strong> (or joint density) of observing them all together <strong>is the product of the individual probabilities</strong> (or densities). This rule follows directly from Kolmogorov’s axioms together with the definition of independence. However, this product can become extremely small as the sample size grows: multiplying many numbers smaller than one can make the result so close to zero that the computer rounds it to zero, a problem known as <strong>numerical underflow.</strong></p>
<p>To avoid this, <strong>we work with the logarithm of the likelihood</strong>, which <strong>turns the product into a sum</strong> and keeps the values within a more stable numerical range. Since the logarithm is a monotonic transformation, maximizing the log-likelihood is equivalent to maximizing the likelihood: <span class="math display">\[
\log \mathcal{L}\left({\color{#9a2515}\theta}\mid{\color{seagreen}Y}\right)
= \sum^n_{i=1}
\log\,{\color{#7E57C2}f}\!\left(
  {\color{seagreen}Y_i}\mid{\color{#9a2515}\theta}
\right)
\]</span></p>
<p>For our exponential example, this becomes <span class="math display">\[
\log \mathcal{L}\left({\color{#9a2515}\lambda}\mid{\color{seagreen}Y}\right)
= \sum^n_{i=1}
\log\!\left(
  {\color{#7E57C2}\mathrm{Exponential}}\!\left(
    {\color{seagreen}Y_i}\mid{\color{#9a2515}\lambda}
  \right)
\right)
\]</span></p>
<p>As before, what looks heavy in notation turns out to be delightfully simple in <code>R</code>. The joint log-likelihood is just the sum of log-densities. For the exponential model evaluated at <span class="math inline">\(\lambda = 2\)</span>:</p>
<div class="cell">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Log-Likelihood</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">dexp</a></span><span class="op">(</span><span class="va">Y</span>, rate <span class="op">=</span> <span class="fl">2</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -35.25715</code></pre>
</div>
</div>
<p>We can also illustrate how to compute the joint log-likelihood under different models evaluated at the same reference parameters:</p>
<div class="cell">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Compute Log-Likelihoods assuming fixed parameter values</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  normal <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">Y</span>, mean <span class="op">=</span> <span class="fl">1.5</span>, sd <span class="op">=</span> <span class="fl">1</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  chi_sq <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">dchisq</a></span><span class="op">(</span><span class="va">Y</span>, df <span class="op">=</span> <span class="fl">2</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  exp    <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">dexp</a></span><span class="op">(</span><span class="va">Y</span>, rate <span class="op">=</span> <span class="fl">2</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     normal    chi_sq       exp
1 -152.9833 -95.45769 -35.25715</code></pre>
</div>
</div>
<p>Here, higher (less negative) values indicate better model fit for these fixed parameter choices.</p>
<p>This is a simple illustration but <strong>not a fair comparison between the three models</strong>, because we have not estimated the parameters using the same data. In fact, <u><strong>we have not estimated anything by maximum likelihood yet</strong></u>. The next code shows how to obtain <span class="math inline">\(\lambda\)</span> for the exponential model and <span class="math inline">\(\nu\)</span><a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> for the <span class="math inline">\(\chi^2\)</span> model by computing the log-likelihood with all the data at once and choosing the value that maximizes it:</p>
<div class="cell">
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Grids with 49000 rate and nu values</span></span>
<span><span class="va">lambda_vals</span> <span class="op">&lt;-</span> <span class="va">nu_vals</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">50</span>, <span class="fl">.001</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Vector to store log-likelihood values</span></span>
<span><span class="va">ll_exp_vals</span> <span class="op">&lt;-</span> <span class="va">ll_chisq_vals</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">lambda_vals</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># For loop: compute log-likelihood for each lambda value</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq_along</a></span><span class="op">(</span><span class="va">lambda_vals</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">ll_exp_vals</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">dexp</a></span><span class="op">(</span><span class="va">Y</span>, rate <span class="op">=</span> <span class="va">lambda_vals</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">ll_chisq_vals</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">dchisq</a></span><span class="op">(</span><span class="va">Y</span>, df <span class="op">=</span> <span class="va">nu_vals</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Maximum-likelihood lambda estimate</span></span>
<span><span class="va">MLE_lambda</span> <span class="op">&lt;-</span> <span class="va">lambda_vals</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.max</a></span><span class="op">(</span><span class="va">ll_exp_vals</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">MLE_nu</span>     <span class="op">&lt;-</span> <span class="va">nu_vals</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.max</a></span><span class="op">(</span><span class="va">ll_chisq_vals</span><span class="op">)</span><span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For the normal distribution, we need to estimate two parameters: <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>. To keep the illustration consistent with the other two models, we’ll estimate them “by brute force”: we create a matrix with two columns, one for <span class="math inline">\(\mu\)</span> values and one for <span class="math inline">\(\sigma\)</span> values. Each row represents a combination of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> where we evaluate the log-likelihood, and we then select the row that maximizes it.</p>
<div class="cell">
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Mu and sigma values</span></span>
<span><span class="va">mu_vals</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">Y</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">Y</span><span class="op">)</span>, <span class="fl">.01</span><span class="op">)</span></span>
<span><span class="va">sigma_vals</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">.0001</span>, <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">Y</span><span class="op">)</span> <span class="op">*</span> <span class="fl">3</span>, <span class="fl">.01</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># All combinations of mu and sigma values</span></span>
<span><span class="va">comb_vals</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html">expand.grid</a></span><span class="op">(</span>mu <span class="op">=</span> <span class="va">mu_vals</span>, sigma <span class="op">=</span> <span class="va">sigma_vals</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Empty vector to save log-likelihood values</span></span>
<span><span class="va">ll_vals</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">comb_vals</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Save values for each combination of mu and sigma</span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">comb_vals</span><span class="op">)</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">ll_vals</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">Y</span>, mean <span class="op">=</span> <span class="va">comb_vals</span><span class="op">[</span><span class="va">i</span>,<span class="fl">1</span><span class="op">]</span>, sd <span class="op">=</span> <span class="va">comb_vals</span><span class="op">[</span><span class="va">i</span>,<span class="fl">2</span><span class="op">]</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Maximum-likelihood estimators</span></span>
<span><span class="va">MLE_mu</span> <span class="op">&lt;-</span> <span class="va">comb_vals</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.max</a></span><span class="op">(</span><span class="va">ll_vals</span><span class="op">)</span>,<span class="st">"mu"</span><span class="op">]</span></span>
<span><span class="va">MLE_sigma</span> <span class="op">&lt;-</span> <span class="va">comb_vals</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.max</a></span><span class="op">(</span><span class="va">ll_vals</span><span class="op">)</span>,<span class="st">"sigma"</span><span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>With the maximum likelihood estimates obtained, we can compute the total log-likelihood for all data under each model using the estimated parameters. The following code returns a table with these three log-likelihoods.</p>
<div class="cell">
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Compute Log-Likelihoods using ML estimates</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  normal <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">Y</span>, mean <span class="op">=</span> <span class="va">MLE_mu</span>, sd <span class="op">=</span> <span class="va">MLE_sigma</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  chi_sq <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">dchisq</a></span><span class="op">(</span><span class="va">Y</span>, df <span class="op">=</span> <span class="va">MLE_nu</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  exp    <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">dexp</a></span><span class="op">(</span><span class="va">Y</span>, rate <span class="op">=</span> <span class="va">MLE_lambda</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     normal    chi_sq       exp
1 -75.87007 -59.26746 -35.15573</code></pre>
</div>
</div>
<p>What we are doing here is informative, but in real applications <u><strong>it would not be enough to decide which model fits best</strong></u>. More robust approaches build precisely on the same idea (the log density as a measure of fit) but extend it through cross-validation or information criteria that penalize model complexity, such as AIC or BIC. The goal here is simply to show how likelihood provides the foundation for these more advanced methods.</p>
</section></section><section id="posterior-reflections4" class="level2"><h2 class="anchored" data-anchor-id="posterior-reflections4">Posterior Reflections<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>
</h2>
<p>Now that we’ve gone through it all, we can finally say what a statistical model is, both in spirit and in form. Formally, a model is <strong>a collection of probability distributions</strong>, one for each value of its parameters<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>. Each distribution tells us <strong>how probability is spread across the data we might see</strong>, and it can be evaluated at the data we actually observed. When we hold the data fixed and let the parameters vary, the same object gives us the <strong>likelihood</strong>, which measures <strong>how compatible each parameter value is with what we saw.</strong></p>
<p>That’s the common language behind every model, from the simplest linear regression to the most elaborate hierarchical model. Once you see that, statistics stops looking like a forest of formulas and starts feeling like what it truly is: a way of reasoning about uncertainty.</p>
<p>When you understand this, the rest of statistics starts to unfold naturally. If a model can assign probability to what we’ve seen, it can help us find the parameter values that make those observations most likely (something we’ve already done throughout this post) and also <strong>quantify how uncertain we are about those estimates</strong> (a step we haven’t explored here). From there, we can evaluate whether <strong>one explanation fits the data better than another</strong>, and even use what we’ve learned to <strong>predict what future data might look like</strong>. It’s the same reasoning, just applied in different directions.</p>
<p>So if someone asks whether you know what a statistical model is, you can smile and say: “<em>It’s probable, in every sense of the word</em> <a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>.”</p>
</section><section id="extra-beyond-the-grid" class="level2"><h2 class="anchored" data-anchor-id="extra-beyond-the-grid">Extra: beyond the grid</h2>
<section id="maximum-likelihood-with-optimization-algorithms" class="level3"><h3 class="anchored" data-anchor-id="maximum-likelihood-with-optimization-algorithms">Maximum likelihood with optimization algorithms</h3>
<p>The grid approach we used is useful for teaching but inefficient in practice. As the number of parameters grows, it quickly becomes computationally impossible. For this reason, maximum likelihood estimation is usually obtained using numerical optimization algorithms.</p>
<p>We will not go into the details of these methods here, but it is useful to see how they work in practice. The code below shows how to use the optim function in R to estimate the parameters by maximum likelihood for the three models. The results are equivalent to those from the grid search, but this approach can generalize to a much wider range of situations.</p>
<div class="cell">
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Log-likelihood functions: gaussian model</span></span>
<span><span class="va">ll_norm</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">par</span>, <span class="va">y</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">mu</span>        <span class="op">&lt;-</span> <span class="va">par</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span>
<span>  <span class="va">sigma</span>     <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">par</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>              <span class="co"># sigma &gt; 0</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">y</span>, mean <span class="op">=</span> <span class="va">mu</span>, sd <span class="op">=</span> <span class="va">sigma</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Log-likelihood functions: exponential model</span></span>
<span><span class="va">ll_exp</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">par</span>, <span class="va">y</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">lambda</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">par</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>                 <span class="co"># lambda &gt; 0</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">dexp</a></span><span class="op">(</span><span class="va">y</span>, rate <span class="op">=</span> <span class="va">lambda</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Log-likelihood functions: chi-square model</span></span>
<span><span class="va">ll_chisq</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">par</span>, <span class="va">y</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">nu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">par</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>                     <span class="co"># nu &gt; 0</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">dchisq</a></span><span class="op">(</span><span class="va">y</span>, df <span class="op">=</span> <span class="va">nu</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Starting values for the optimizer</span></span>
<span><span class="va">norm_svals</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">.1</span>,<span class="fl">.1</span><span class="op">)</span></span>
<span><span class="va">exp_svals</span> <span class="op">&lt;-</span> <span class="fl">.1</span> </span>
<span><span class="va">chisq.svals</span> <span class="op">&lt;-</span> <span class="fl">.1</span></span>
<span></span>
<span><span class="co"># ML estimation via optim</span></span>
<span><span class="va">fit_norm</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/optim.html">optim</a></span><span class="op">(</span><span class="va">norm_svals</span>,  <span class="va">ll_norm</span>,  y <span class="op">=</span> <span class="va">Y</span>, method <span class="op">=</span> <span class="st">"BFGS"</span>, </span>
<span>                   control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>fnscale <span class="op">=</span> <span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">fit_exp</span>   <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/optim.html">optim</a></span><span class="op">(</span><span class="va">exp_svals</span>, <span class="va">ll_exp</span>,   y <span class="op">=</span> <span class="va">Y</span>, method <span class="op">=</span> <span class="st">"BFGS"</span>, </span>
<span>                   control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>fnscale <span class="op">=</span> <span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">fit_chisq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/optim.html">optim</a></span><span class="op">(</span><span class="va">chisq.svals</span>, <span class="va">ll_chisq</span>, y <span class="op">=</span> <span class="va">Y</span>, method <span class="op">=</span> <span class="st">"BFGS"</span>, </span>
<span>                   control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>fnscale <span class="op">=</span> <span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Extract MLEs</span></span>
<span><span class="va">MLE_mu</span>     <span class="op">&lt;-</span> <span class="va">fit_norm</span><span class="op">$</span><span class="va">par</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span>
<span><span class="va">MLE_sigma</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">fit_norm</span><span class="op">$</span><span class="va">par</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">MLE_lambda</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">fit_exp</span><span class="op">$</span><span class="va">par</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">MLE_nu</span>     <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">fit_chisq</span><span class="op">$</span><span class="va">par</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Log-likelihoods at MLEs</span></span>
<span><span class="va">LL_normal</span> <span class="op">&lt;-</span> <span class="va">fit_norm</span><span class="op">$</span><span class="va">value</span></span>
<span><span class="va">LL_exp</span>    <span class="op">&lt;-</span> <span class="va">fit_exp</span><span class="op">$</span><span class="va">value</span></span>
<span><span class="va">LL_chisq</span>  <span class="op">&lt;-</span> <span class="va">fit_chisq</span><span class="op">$</span><span class="va">value</span></span>
<span></span>
<span><span class="co"># Summary table</span></span>
<span><span class="va">MLE_table</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Normal"</span>, <span class="st">"Exponential"</span>, <span class="st">"Chi-square"</span><span class="op">)</span>,</span>
<span>  param_1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"mu = %.6f"</span>, <span class="va">MLE_mu</span><span class="op">)</span>,</span>
<span>              <span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"lambda = %.6f"</span>, <span class="va">MLE_lambda</span><span class="op">)</span>,</span>
<span>              <span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"nu = %.6f"</span>, <span class="va">MLE_nu</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  param_2 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"sigma = %.6f"</span>, <span class="va">MLE_sigma</span><span class="op">)</span>, <span class="st">""</span>, <span class="st">""</span><span class="op">)</span>,</span>
<span>  logLik  <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">LL_normal</span>, <span class="va">LL_exp</span>, <span class="va">LL_chisq</span><span class="op">)</span>,</span>
<span>  row.names <span class="op">=</span> <span class="cn">NULL</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">MLE_table</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>        model           param_1          param_2    logLik
1      Normal     mu = 0.522859 sigma = 0.516706 -75.86575
2 Exponential lambda = 1.912560                  -35.15572
3  Chi-square     nu = 1.040636                  -59.26745</code></pre>
</div>
</div>
</section><section id="closed-form-maximum-likelihood-solutions" class="level3"><h3 class="anchored" data-anchor-id="closed-form-maximum-likelihood-solutions">Closed-form maximum likelihood solutions</h3>
<p>If you made it this far, congratulations: we have gone step by step through the full path of maximum likelihood estimation. We have tried values by hand, done grid searches, and used a numerical optimizer. And now, just when it seems we have done it all, comes a small plot twist: in some cases, everything can be solved with a single formula.</p>
<p>It almost sounds unfair, right? After spending so much effort understanding the logic of likelihood, it turns out that for some distributions the exact solution can be written in one line. But that is precisely why the long path is worth it: those formulas are no longer mysterious recipes, but the natural conclusion of a story that now makes sense.</p>
<p>For the Normal and Exponential models, the maximum likelihood estimators have closed-form solutions, meaning they can be obtained directly from the properties of the distributions without iterative algorithms.</p>
<p>For the Normal distribution, the parameters that maximize the likelihood are the sample mean and the sample standard deviation (using <span class="math inline">\(1/n\)</span> instead of <span class="math inline">\(1/(n-1)\)</span> because here we want the value that maximizes the likelihood, not an unbiased estimator):</p>
<p><span class="math display">\[
\hat\mu_\text{ML}=\frac{1}{n}\cdot\sum^n_{i=1}Y_{i},\qquad \hat\sigma_\text{ML}=\sqrt{\frac{1}{n}\sum^n_{i=1}\left(Y_i-\hat\mu_\text{ML}\right)^2}
\]</span></p>
<div class="cell">
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="op">(</span><span class="va">MLE_mu_closed</span>    <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">Y</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.5228594</code></pre>
</div>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="op">(</span><span class="va">MLE_sigma_closed</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">Y</span> <span class="op">-</span> <span class="va">MLE_mu_closed</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.5167061</code></pre>
</div>
</div>
<p>For the Exponential distribution, the maximum likelihood estimator of the rate parameter <span class="math inline">\(\lambda\)</span> is also obtained directly:</p>
<p><span class="math display">\[
\hat\lambda_\text{ML}=\frac{n}{\sum^n_{i=1}Y_i}
\]</span></p>
<div class="cell">
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="op">(</span><span class="va">MLE_lambda_closed</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">Y</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">Y</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.91256</code></pre>
</div>
</div>
<p>These two expressions exactly match the values we obtained with the optimization algorithm. For the <span class="math inline">\(\chi^2\)</span> distribution, however, there is no closed-form solution, and its estimation necessarily requires numerical methods.</p>


</section></section><a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>
<ol>
<li id="fn1"><p>Note that we are <strong>not</strong> talking about the probability of a single, exact value. For continuous variables, that probability is always zero. What continuous models provide instead is a <em>density</em>, which tells us how probability is distributed across possible values.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Any outraged reader may address their complaints to Sir Ronald Fisher, or demand that, before naming things, statisticians must submit each new term to a linguistic ethics committee.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>We’ll let <span class="math inline">\(\nu\)</span> be any positive real number. Although textbooks often introduce <span class="math inline">\(\nu\)</span> as an integer (“degrees of freedom”), the <span class="math inline">\(\chi^2\)</span> family extends smoothly to non-integers and is equivalent to a Gamma distribution with shape = <span class="math inline">\(\nu/2\)</span> and scale = 2. We do this just to keep the example simple and focus on likelihood. (And yes, in <code>R</code>, <code><a href="https://rdrr.io/r/stats/Chisquare.html">dchisq()</a></code> works for non-integer <span class="math inline">\(\nu\)</span>).<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>You came here knowing something, you’ve read the post, and now what you knew might have shifted a bit, huh? I know, I know… I’ll see myself out… and wait for you there…<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>Even more formally, a (parametric) statistical model is a family of distributions <span class="math inline">\(\mathcal{M}=\left\{{\color{#7E57C2}f}\left({\color{seagreen}y}\mid{\color{#9a2515}\theta}\right):{\color{#9a2515}\theta}\in{\color{#9a2515}\Theta}\right\}\)</span>, where <span class="math inline">\({\color{#7E57C2}f}\left({\color{seagreen}y}\mid{\color{#9a2515}\theta}\right)\)</span> is a probability density (or mass) function on the <strong>sample space</strong> (the set of all possible values that the data <span class="math inline">\({\color{seagreen}y}\)</span> can take), and <span class="math inline">\({\color{#9a2515}\Theta}\)</span> is the <strong>parameter space</strong> (the set of all possible values that the parameters <span class="math inline">\({\color{#9a2515}\theta}\)</span> can take).<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>However, be careful when the same person asks you what probability is. That’s how most of us die.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol></section><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a></div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-rey-sáez2025" class="csl-entry quarto-appendix-citeas" role="listitem">
Rey-Sáez, Ricardo. 2025. <span>“What Is a Statistical Model? From
Density to Likelihood.”</span> October 13, 2025. <a href="https://ricardoreysaez.github.io/blog/model_definition/">https://ricardoreysaez.github.io/blog/model_definition/</a>.
</div></div></section></div></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    window.setColorSchemeToggle(window.hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/ricardoreysaez\.github\.io\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p>© 2025 Ricardo Rey-Sáez ∙ Made with ❤️, ChatGPT and <a href="https://quarto.org" target="_blank" rel="noopener">Quarto</a></p>
</div>   
    <div class="nav-footer-center">
<p><a class="link-dark me-1" href="https://orcid.org/0000-0001-6739-2035" title="ORCID" target="_blank" rel="noopener"><iconify-icon role="img" inline="" icon="fa6-brands:orcid" aria-label="Icon orcid from fa6-brands Iconify.design set." title="Icon orcid from fa6-brands Iconify.design set."></iconify-icon></a> <a class="link-dark me-1" href="https://github.com/rreysa" title="GitHub" target="_blank" rel="noopener"><iconify-icon role="img" inline="" icon="fa6-brands:github" aria-label="Icon github from fa6-brands Iconify.design set." title="Icon github from fa6-brands Iconify.design set."></iconify-icon></a> <a class="link-dark me-1" href="https://www.researchgate.net/profile/Ricardo-Rey-Saez" title="ResearchGate" target="_blank" rel="noopener"><iconify-icon role="img" inline="" icon="fa6-brands:researchgate" aria-label="Icon researchgate from fa6-brands Iconify.design set." title="Icon researchgate from fa6-brands Iconify.design set."></iconify-icon></a> <a class="link-dark me-1" href="https://x.com/RicardoRey_95" title="Twitter/X" target="_blank" rel="noopener"><iconify-icon role="img" inline="" icon="fa6-brands:twitter" aria-label="Icon twitter from fa6-brands Iconify.design set." title="Icon twitter from fa6-brands Iconify.design set."></iconify-icon></a> <a class="link-dark me-1" href="https://bsky.app/profile/ricardoreysaez.bsky.social" title="Bluesky" target="_blank" rel="noopener"><iconify-icon role="img" inline="" icon="fa6-brands:bluesky" aria-label="Icon bluesky from fa6-brands Iconify.design set." title="Icon bluesky from fa6-brands Iconify.design set."></iconify-icon></a> <a class="link-dark me-1" href="https://www.youtube.com/@psicometries" title="YouTube" target="_blank" rel="noopener"><iconify-icon role="img" inline="" icon="fa6-brands:youtube" aria-label="Icon youtube from fa6-brands Iconify.design set." title="Icon youtube from fa6-brands Iconify.design set."></iconify-icon></a></p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer><script>
(function () {
  function setup() {
    // Contenedor del botón de cambio de tema
    const wrap = document.querySelector('.quarto-color-scheme-toggle');
    if (!wrap || wrap.querySelector('iconify-icon')) return;

    // Inserta directamente los iconos dentro del botón
    wrap.innerHTML = `
      <span class="q-scheme-icons" aria-hidden="true">
        <iconify-icon class="icon-sun"  icon="lucide:sun"  width="22" height="22"></iconify-icon>
        <iconify-icon class="icon-moon" icon="lucide:moon" width="22" height="22"></iconify-icon>
      </span>`;

    // Actualiza visibilidad según modo actual
    updateIcons();

    // Escucha cambios de tema
    wrap.addEventListener('click', () => {
      setTimeout(updateIcons, 20); // pequeño retardo para transición
    });
  }

  // Muestra/oculta los iconos según el tema activo
  function updateIcons() {
    const isDark = document.body.classList.contains('quarto-dark');
    const sun  = document.querySelector('.q-scheme-icons .icon-sun');
    const moon = document.querySelector('.q-scheme-icons .icon-moon');
    if (!sun || !moon) return;
    sun.style.opacity  = isDark ? 0 : 1;
    moon.style.opacity = isDark ? 1 : 0;
  }

  // Ejecutar al cargar la página
  (document.readyState === 'loading')
    ? document.addEventListener('DOMContentLoaded', setup)
    : setup();
})();
</script><style>
/* Contenedor general del botón */
.navbar .quarto-color-scheme-toggle {
  display: inline-flex;
  align-items: center;
  justify-content: center;
  padding: 0 .2rem;
  cursor: pointer;
  position: relative;
  top: 4px;
}

/* Contenedor interno de los iconos */
.q-scheme-icons {
  display: inline-flex;
  align-items: center;
  justify-content: center;
  position: relative;
  width: 1.1rem;
  height: 1.6rem;
  transform: translateY(2px);
}

/* Iconos centrados con transición */
.q-scheme-icons iconify-icon {
  position: absolute;
  line-height: 1;
  vertical-align: middle;
  transition: opacity .25s ease;
}

/* Sol y luna por defecto */
.q-scheme-icons .icon-sun  { opacity: 1; }
.q-scheme-icons .icon-moon { opacity: 0; }

/* En modo oscuro, intercambiar */
body.quarto-dark .q-scheme-icons .icon-sun  { opacity: 0; }
body.quarto-dark .q-scheme-icons .icon-moon { opacity: 1; }
</style>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>


</body></html>